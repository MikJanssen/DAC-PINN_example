{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of code for interview Capgemini from DAC-PINN.  \n",
    "Contents:\n",
    "- library imports\n",
    "- parameters struct.\n",
    "- NN architecture.\n",
    "- Physics loss calculation.\n",
    "- Dynamic loss weight scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.constants import gas_constant as R_gas\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyDOE import lhs\n",
    "from scipy import io, stats\n",
    "from scipy.stats import qmc\n",
    "import random\n",
    "import time\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for some basics of the modeled system:\n",
    "- Naming of modeled species.\n",
    "- Importing of all solid species data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for model in symetrical conditions\n",
    "class parameters():\n",
    "    #System description and geometry\n",
    "    L = 0.025                       # column lenght [m]    \n",
    "    R = 0.0025                      # column radius [m]\n",
    "    eps_b = 0.5                     # packed-bed porosity [-]\n",
    "    rho_p = 744                     # bed density [kg/m3] \n",
    "    v_in = 0.1                      # axial velocity [m/s]\n",
    "    diff_p = 2e-6                   # [m/s]\n",
    "    D_ax = 7e-4                     # [m2/s]\n",
    "    D_rad = 1.57e-5                 # [m2/s]             \n",
    "    R_p = 0.25e-3                   # [m]\n",
    "\n",
    "    #Variables needed for data NN:\n",
    "    inputs = 2\n",
    "    num_outputs = faces_data.shape[2]   # number of ouptuts to predict\n",
    "    dt = 10                             # time step [s]\n",
    "    t_end = 8000                        # total simulated time [s]\n",
    "    Nx = 100                            # number of gridpoints [-]\n",
    "\n",
    "    x_f = np.linspace(0, L, Nx + 1)     # spatial coordinates of the cell faces [m]\n",
    "    x_c = 0.5 * (x_f[:-1] + x_f[1:])    # spatial coordinates of the cell centers [m]\n",
    "\n",
    "    t = np.linspace(0, t_end, int(t_end/dt) + 1)    # time grid [s]                       \n",
    "    x = np.concatenate((0, x_c), axis=None)         # inlet + cell centers [m]\n",
    "\n",
    "    x_combined = np.zeros(Nx * 2 + 1)\n",
    "\n",
    "    # Interplace x_f and x_c\n",
    "    x_combined[0::2] = x_f\n",
    "    x_combined[1::2] = x_c\n",
    "    \n",
    "    x = x_combined\n",
    "\n",
    "    #Physical parameters\n",
    "    T_feed = 25 + 273.15                  # feed temperature [K]\n",
    "    T_initial = 25 + 273.15               # initial temperature [K]\n",
    "    T_0 = T_initial\n",
    "    T_max = faces_data[:,:,2].max()       # max temperature [K]\n",
    "\n",
    "    frac_CO2 = 400e-6                     # CO2 fraction in the feed [-]\n",
    "    p_CO2_initial = 0                     # initial CO2 pressure [Pa]\n",
    "    p_CO2_feed = frac_CO2 * 101325        # feed CO2 pressure [Pa]\n",
    "\n",
    "    p_tot_initial = 101325                # initial total pressure [Pa]\n",
    "    p_tot_feed = 101325                   # feed total pressure [Pa]\n",
    "\n",
    "    MW_CO2 = 44.01/1000                   # molar weight CO2 [kg/mol]\n",
    "    MW_N2 = 28.0134/1000                  # molar weight N2 [kg/mol]\n",
    "    \n",
    "    c_CO2g_feed = p_CO2_feed / R_gas / T_initial + 1e-32        # CO2 gas feed concentration [mol/m3]\n",
    "    c_N2_feed = (p_tot_feed - p_CO2_feed ) / R_gas / T_feed     # N2 gas feed concentration [mol/m3]\n",
    "    MW_f = 0.02813337934579806\n",
    "    rho_f = 1.149925                                            # gas feed density [kg/m3]\n",
    "    mass_frac_CO2 = c_CO2g_feed * MW_CO2 / rho_f                # CO2 mass fraction in the feed [-]\n",
    "\n",
    "    a_Cp_p = -3.23e7             # specific heat capacity coefficient particle 'a' [J/K/kg] (Low 2023)\n",
    "    b_Cp_p = 2.27                # specific heat capacity coefficient particle 'b' [J/kg/K^2] (Low 2023)\n",
    "    c_Cp_p = -994                # specific heat capacity coefficient particle 'c' [J/kg/K] (Low 2023)\n",
    "    Cp_g_CO2= 0.84*1000          # specific heat capacity CO2g [J/kg/K] (298K, 1atm) The Engineering Toolbox\n",
    "    Cp_g_N2= 1.04*1000           # specific heat capacity N2g [J/kg/K] (298K, 1atm) The Engineering Toolbox  \n",
    "\n",
    "    Cp_p = 1307.444              # specific heat capacity particle [J/kg/K] (Low 2023)\n",
    "    Cp_f = 29.123/MW_f           # specific heat capacity gas [J/kg/K]\n",
    "\n",
    "    rho_Cp_ov = (1-eps_b) * rho_p * Cp_p + eps_b * rho_f * Cp_f    # overall heat capacity [J/m3/K]\n",
    "\n",
    "    lambda_CO2g= 0.0166          # thermal conductivity CO2g [W/m/K] (298K, 1atm) The Engineering Toolbox\n",
    "    lambda_p =  0.43             # thermal conducitvity particle [W/m/K] (Bos 2019)\n",
    "    lambda_ov = 0.21             # overall thermal conductivity [W/m/K]\n",
    "\n",
    "    alpha = lambda_ov / (rho_Cp_ov)          # non-dimensional thermal diffusivity [m2/s]\n",
    "\n",
    "    v_superficial = v_in/eps_b               # superficial velocity [m/s]\n",
    "\n",
    "    #Kinetic parametrs  \n",
    "    k_LDF = 0.005                 # adsorption rate constant[1/s] \n",
    "\n",
    "    DH0_CO2 = -70125              # Heat of CO2 adsorption [J/mol] (Low 2023)  \n",
    "    \n",
    "    #Thot isotherm parameteres (Young data)\n",
    "    q_m = 4.86          # [mol/kg]\n",
    "    T0 = 298.15         # [K]\n",
    "    b0 = 2.85e-21       # [1/Pa]\n",
    "    DH0 = -117789       # [J/mol]\n",
    "    th0 = 0.209\n",
    "    beta = 0.523\n",
    "    Young_fact = np.exp(-DH0/R_gas/T_0)\n",
    "\n",
    "    b_in  = b0 * Young_fact\n",
    "\n",
    "    #Parameters for non-dimensionalization\n",
    "    c_0 = c_CO2g_feed                                                   # reference concentration [mol/m3]\n",
    "    ux_0 = v_superficial                                                # reference velocity [m/s]\n",
    "    q_0 = q_m*b_in*p_CO2_feed/((1+(b_in*p_CO2_feed)**th0)**(1/th0))     # reference solid concentration (saturation concentration at inlet condition) [mol/kg]\n",
    "    DeltaT = T_max - T_feed                                             # reference temperature difference [K]\n",
    "    tau = L / ux_0                                                      # reference time [s]\n",
    "\n",
    "    Da_I = k_LDF * tau                                                  # non-dimensional adsorption rate constant [-]\n",
    "    theta = q_0 * (-DH0_CO2) / (rho_Cp_ov * DeltaT) * rho_p * (1-eps_b) # non-dimensional heat of adsorption [-]\n",
    "    \n",
    "    Pe_f = ux_0 * L / D_ax                            # Peclet number for flow [-]\n",
    "    Pe_h = ux_0 * L / alpha                           # Peclet number for heat [-]\n",
    "\n",
    "    c_tot = p_tot_feed/R_gas/T_feed                   # maximum possiple gas concentration [-]              \n",
    "\n",
    "    t_nd = t/(tau)                                    # non-dimensional time\n",
    "    x_nd = x_f/L                                      # non-dimensional space\n",
    "    t_nd_mesh, x_nd_mesh = np.meshgrid(t_nd, x_nd, indexing='ij')\n",
    "    \n",
    "p = parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-dimensionalize data:\n",
    "- Plot concentration curves at different timesteps (truth data)\n",
    "- Plot heatmap of total concentration evolution across space-time domain (truth data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output1_cell7](../Results/Pictures/output1_cell7.png)\n",
    "![output2_cell7](../Results/Pictures/output2_cell7.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data and make data sets:\n",
    "- Training, validation and testing data.\n",
    "- Boundary condition data.\n",
    "- Initial condition data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output1_cell11](../Results/Pictures/output1_cell11.png)\n",
    "![output2_cell11](../Results/Pictures/output2_cell11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create PINN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient function to obtain gradients of the activation functions\n",
    "\n",
    "def grad(y, x):\n",
    "    return torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "\n",
    "class testnet(nn.Module):   \n",
    "    def __init__(self, outputs = p.num_outputs, inputs = p.inputs, nodes =96):\n",
    "        super(testnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputs, nodes)\n",
    "        self.act1 = nn.Tanh()\n",
    "\n",
    "        self.fc2 = nn.Linear(nodes, nodes)\n",
    "        self.act2 = nn.Tanh()\n",
    "\n",
    "        self.fc3 = nn.Linear(nodes, nodes)\n",
    "        self.act3 = nn.Tanh()\n",
    "\n",
    "        self.fc4 = nn.Linear(nodes, nodes)\n",
    "        self.act4= nn.Tanh()\n",
    "\n",
    "        self.fc5 = nn.Linear(nodes, outputs)\n",
    "        self.act5 = nn.Sigmoid()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "                    self.fc1, self.act1, \n",
    "                    self.fc2, self.act2, \n",
    "                    self.fc3, self.act3, \n",
    "                    self.fc4, self.act4, \n",
    "                    self.fc5, self.act5\n",
    "                    )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def get_u(self, x):\n",
    "        u = self.forward(x)\n",
    "        return u[:,0], u[:,1], u[:,2]\n",
    "\n",
    "    def get_gradu(self, x):\n",
    "        co2g, co2s, T = self.get_u(x)\n",
    "        co2g_t, co2g_x = grad(co2g, x)[:,0], grad(co2g, x)[:,1]\n",
    "        co2s_t, co2s_x = grad(co2s, x)[:,0], grad(co2s, x)[:,1]\n",
    "        T_t, T_x = grad(T, x)[:,0], grad(T, x)[:,1]\n",
    "        return co2g_t, co2s_t, T_t, co2g_x, co2s_x, T_x\n",
    "    \n",
    "    def get_grad2u(self,x):\n",
    "        _, _, _, co2g_x, _, T_x = self.get_gradu(x)\n",
    "        co2g_xx = grad(co2g_x, x)[:,1]\n",
    "        T_xx = grad(T_x, x)[:,1]\n",
    "        return co2g_xx, T_xx\n",
    "\n",
    "model3comp_non_dim = testnet()\n",
    "model3comp_non_dim = model3comp_non_dim.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create class to get physics loss:\n",
    "- Generate collocation points.\n",
    "- Evaluate physics loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physics loss function\n",
    "\n",
    "def phys_loss(self):\n",
    "    # generate collocation points\n",
    "    lbc, rbc, icpts, pdepts, IC_indices = self.phys_domain_colpts_generator()\n",
    "    #set non-dimensional velocity\n",
    "    ux_nd = p.v_superficial/p.ux_0  #in surrogate model this will be calculated using variables.\n",
    "\n",
    "    #LBC loss Dirichlet\n",
    "    co2g_lbc, _,  T_lbc = self.model.get_u(lbc)\n",
    "    lbc_co2g_nd = 1 - co2g_lbc\n",
    "    lbc_T_nd = T_lbc\n",
    "\n",
    "    LBC_loss_co2g = torch.mean((lbc_co2g_nd)**2)\n",
    "    LBC_loss_T = torch.mean((lbc_T_nd)**2)\n",
    "\n",
    "    #RBC loss Neumann\n",
    "    _, _, _, dx_co2g_rbc, _, dx_T_rbc = self.model.get_gradu(rbc) \n",
    "    rbc_co2g_nd = dx_co2g_rbc\n",
    "    rbc_T_nd = dx_T_rbc\n",
    "\n",
    "    RBC_loss_co2g = torch.mean((rbc_co2g_nd)**2)\n",
    "    RBC_loss_T = torch.mean((rbc_T_nd)**2)\n",
    "    \n",
    "    #IC loss (using data)\n",
    "    cg_ic, cs_ic, T_ic = self.model.get_u(icpts)\n",
    "    Ric_co2g = cg_ic - torch.tensor(np.repeat(data_faces_nd[0,:,0], self.bcpts/p.Nx)[IC_indices], dtype=torch.float32).to(device)\n",
    "    Ric_co2s = cs_ic - torch.tensor(np.repeat(data_faces_nd[0,:,1], self.bcpts/p.Nx)[IC_indices], dtype = torch.float32).to(device)\n",
    "    Ric_T = T_ic - torch.tensor(np.repeat(data_faces_nd[0,:,2], self.bcpts/p.Nx)[IC_indices], dtype = torch.float32).to(device)\n",
    "\n",
    "    IC_loss_co2g = torch.mean((Ric_co2g)**2)\n",
    "    IC_loss_co2s = torch.mean((Ric_co2s)**2)\n",
    "    IC_loss_T = torch.mean((Ric_T)**2)\n",
    "\n",
    "    #PDE losses: obtain derivativse\n",
    "    c_nd, q_nd, T_nd = self.model.get_u(pdepts)\n",
    "    dt_c_nd, dt_q_nd, dt_T_nd, dx_c_nd, _, dx_T_nd = self.model.get_gradu(pdepts)\n",
    "    dxx_c_nd, dxx_T_nd = self.model.get_grad2u(pdepts)\n",
    "\n",
    "    #Calculating equilibrium concentration using Toth isotherm\n",
    "    p_toth = c_nd*p.c_tot*R_gas*(T_nd*p.DeltaT + p.T_0)\n",
    "    b_toth = p.b0 * torch.exp(p.DH0/( R_gas * p.T_0) * (1 - p.T_0/(T_nd * p.DeltaT + p.T_0))) * p.Young_fact\n",
    "    th_toth = p.th0 + p.beta*(1 - p.T_0/(T_nd * p.DeltaT + p.T_0))\n",
    "    q_eq = p.q_m * b_toth * p_toth / ((1 + (b_toth * p_toth)**th_toth)**(1 / th_toth))\n",
    "    q_eq_nd = q_eq/p.q_0\n",
    "\n",
    "    #calculate PDE residuals\n",
    "    pde_co2g = (1/p.t_nd.max())*dt_c_nd +  ux_nd * dx_c_nd  - 1/p.Pe_f * dxx_c_nd \\\n",
    "        + (1-p.eps_b)/p.eps_b * p.q_0/p.c_0 * p.rho_p * p.Da_I * (q_eq_nd - q_nd)\n",
    "\n",
    "    pde_co2s = (1/p.t_nd.max())*dt_q_nd - p.Da_I * (q_eq_nd - q_nd)\n",
    "\n",
    "    pde_T = (1/p.t_nd.max())*dt_T_nd + ux_nd * dx_T_nd - 1/p.Pe_h * dxx_T_nd + p.theta * p.Da_I * (q_eq_nd - q_nd)\n",
    "\n",
    "    PDE_loss_co2g = torch.mean((pde_co2g)**2)\n",
    "    PDE_loss_co2s = torch.mean((pde_co2s)**2)\n",
    "    PDE_loss_T = torch.mean((pde_T)**2)\n",
    "    \n",
    "    return torch.tensor([LBC_loss_co2g, LBC_loss_T, RBC_loss_co2g, RBC_loss_T, IC_loss_co2g, IC_loss_co2s, IC_loss_T, PDE_loss_co2g, PDE_loss_co2s, PDE_loss_T])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader using dataset class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiallize arrays for variable saving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training:\n",
    "- First use ADAM optimizer with curriculum learning.\n",
    "- Then use LBFG optimizer.\n",
    "- Use dynamic loss scaling for multivariable objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMA smoothing function for dynamic loss scaling\n",
    "def compute_ema_and_scale(phys_loss_array, phys_ema_losses, scaling_factors, alpha):\n",
    "\n",
    "    # Update EMA values for each physics loss and compute scaling factors\n",
    "    for i in range(len(phys_loss_array)):\n",
    "        current_loss = phys_loss_array[i].item()\n",
    "\n",
    "        # Initialize EMA value if it's the first epoch\n",
    "        if phys_ema_losses[i] is None:\n",
    "            phys_ema_losses[i] = current_loss\n",
    "        else:\n",
    "            # Update EMA value\n",
    "            phys_ema_losses[i] = alpha * current_loss + (1 - alpha) * phys_ema_losses[i]\n",
    "\n",
    "    # Compute the total EMA loss (sum of all EMA losses)\n",
    "    tot_phys_ema_loss = sum(phys_ema_losses)\n",
    "\n",
    "    # Compute the scaling factor based on the EMA values\n",
    "    for i in range(len(phys_loss_array)):\n",
    "        scaling_factors[i] = tot_phys_ema_loss / (phys_ema_losses[i] + 1e-9)\n",
    "        #scaling_factors[i] = min(scaling_factors[i], 50)  #possibility of adding a clipping factor\n",
    "        \n",
    "    return phys_ema_losses, scaling_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy training losses:  \n",
    "\n",
    "![Dummy loss graphs](../Results/Pictures/Dummy_loss_graphs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best trained networks and predict full domain:\n",
    "- Print error values.\n",
    "- Plot predictions and absolute errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Predicted concentration LBFGS](../Results/Pictures/Predicted_concentration_LBFGS.png)\n",
    "![Absolute error LBFGS](../Results/Pictures/Absolute_error_LBFGS.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
